{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           date                                               text president  \\\n",
       "0    2012-11-05  president obama tells the story of fired up re...     Obama   \n",
       "1    2012-11-06  election day is here confirm your polling plac...     Obama   \n",
       "2    2012-11-07  thank you president obama in his victory speec...     Obama   \n",
       "3    2012-11-08  the definition of hope is you still believe ev...     Obama   \n",
       "4    2012-11-09  what bobby kennedy called the ripples of hope ...     Obama   \n",
       "...         ...                                                ...       ...   \n",
       "1823 2020-06-11  our great national guard troops who took care ...     Trump   \n",
       "1824 2020-06-12  people have no idea how fake the lamestream me...     Trump   \n",
       "1825 2020-06-15  i’ve done more in less than 4 years than biden...     Trump   \n",
       "1826 2020-06-16  wow may retail sales show biggest one-month in...     Trump   \n",
       "1827 2020-06-17  joe biden was a total failure in government he...     Trump   \n",
       "\n",
       "      label  \n",
       "0         0  \n",
       "1         1  \n",
       "2         2  \n",
       "3         2  \n",
       "4         0  \n",
       "...     ...  \n",
       "1823      2  \n",
       "1824      2  \n",
       "1825      1  \n",
       "1826      0  \n",
       "1827      2  \n",
       "\n",
       "[1828 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>text</th>\n      <th>president</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2012-11-05</td>\n      <td>president obama tells the story of fired up re...</td>\n      <td>Obama</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2012-11-06</td>\n      <td>election day is here confirm your polling plac...</td>\n      <td>Obama</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2012-11-07</td>\n      <td>thank you president obama in his victory speec...</td>\n      <td>Obama</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2012-11-08</td>\n      <td>the definition of hope is you still believe ev...</td>\n      <td>Obama</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2012-11-09</td>\n      <td>what bobby kennedy called the ripples of hope ...</td>\n      <td>Obama</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1823</th>\n      <td>2020-06-11</td>\n      <td>our great national guard troops who took care ...</td>\n      <td>Trump</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1824</th>\n      <td>2020-06-12</td>\n      <td>people have no idea how fake the lamestream me...</td>\n      <td>Trump</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1825</th>\n      <td>2020-06-15</td>\n      <td>i’ve done more in less than 4 years than biden...</td>\n      <td>Trump</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1826</th>\n      <td>2020-06-16</td>\n      <td>wow may retail sales show biggest one-month in...</td>\n      <td>Trump</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1827</th>\n      <td>2020-06-17</td>\n      <td>joe biden was a total failure in government he...</td>\n      <td>Trump</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>1828 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_excel('../Adatok/tisztitott_adat.xlsx', header=0,index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "label = data['label']\n",
    "attrs = data['text']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        attrs, label, test_size=0.25, random_state=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "183     the first week of #actionaugust is coming to a...\n",
       "564     it's time to end the era of manufactured crise...\n",
       "453     watch a special pep talk for on women's equali...\n",
       "1243    as we come together to celebrate the extraordi...\n",
       "251     continue to stand up against discrimination ad...\n",
       "                              ...                        \n",
       "1275    our border laws are very weak while those of m...\n",
       "1728    the democrat controlled house never even asked...\n",
       "71      for the sake of future gun victimslawmakers sh...\n",
       "599     live the white house is hosting the eighth ann...\n",
       "1459    just returned from visiting our troops in iraq...\n",
       "Name: text, Length: 1371, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(data['text'])\n",
    "\n",
    "max_length = max([len(s.split()) for s in data['text']])\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "X_train_token = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_token = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_token, maxlen=max_length, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_token, maxlen=max_length, padding='post')\n"
   ]
  },
  {
   "source": [
    "# .............................\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "source": [
    "## Basic NN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 10)                11520     \n_________________________________________________________________\ndense_1 (Dense)              (None, 3)                 33        \n=================================================================\nTotal params: 11,553\nTrainable params: 11,553\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_pad.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='sigmoid'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Accuracy: 0.5799\nTesting Accuracy:  0.5886\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pad, y_train,\n",
    "                    epochs=25,\n",
    "                    verbose=False,\n",
    "                    validation_data=(X_test_pad, y_test),\n",
    "                    batch_size=10)\n",
    "loss, accuracy = model.evaluate(X_train_pad, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "source": [
    "## Embedding Layer + Flatten added\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 1151, 50)          738700    \n_________________________________________________________________\nflatten (Flatten)            (None, 57550)             0         \n_________________________________________________________________\ndropout (Dropout)            (None, 57550)             0         \n_________________________________________________________________\ndense (Dense)                (None, 10)                575510    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 10)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 3)                 33        \n=================================================================\nTotal params: 1,314,243\nTrainable params: 1,314,243\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=max_length,\n",
    "                           trainable=True))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(3, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Accuracy: 0.7433\nTesting Accuracy:  0.5886\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pad, y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=False,\n",
    "                    validation_data=(X_test_pad, y_test),\n",
    "                    batch_size=10)\n",
    "loss, accuracy = model.evaluate(X_train_pad, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "source": [
    "## Embedding + Pooling added\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 1151, 50)          738700    \n_________________________________________________________________\nglobal_max_pooling1d (Global (None, 50)                0         \n_________________________________________________________________\ndense (Dense)                (None, 10)                510       \n_________________________________________________________________\ndropout (Dropout)            (None, 10)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 3)                 33        \n=================================================================\nTotal params: 739,243\nTrainable params: 739,243\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=max_length,\n",
    "                           trainable=True))\n",
    "model.add(layers.GlobalMaxPool1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(3, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Accuracy: 0.7411\nTesting Accuracy:  0.5799\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pad, y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=False,\n",
    "                    validation_data=(X_test_pad, y_test),\n",
    "                    batch_size=10)\n",
    "loss, accuracy = model.evaluate(X_train_pad, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "source": [
    "## CNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 1151, 50)          738700    \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 1151, 50)          0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 1147, 128)         32128     \n_________________________________________________________________\nglobal_max_pooling1d_1 (Glob (None, 128)               0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                1290      \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 10)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 3)                 33        \n=================================================================\nTotal params: 772,151\nTrainable params: 772,151\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size,embedding_dim, input_length=max_length, trainable=True))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(3, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Accuracy: 0.7739\n",
      "Testing Accuracy:  0.5624\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pad, y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=False,\n",
    "                    validation_data=(X_test_pad, y_test),\n",
    "                    batch_size=10)\n",
    "loss, accuracy = model.evaluate(X_train_pad, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}